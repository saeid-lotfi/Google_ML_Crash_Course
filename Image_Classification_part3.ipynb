{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of image_classification_part3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jTEzoMx6CasV"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saeid-lotfi/Google_ML_Crash_Course/blob/main/Image_Classification_part3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTEzoMx6CasV"
      },
      "source": [
        "#### Copyright 2018 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhmPj1VVCfWb"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHK6DyunSbs4"
      },
      "source": [
        "# Cat vs. Dog Image Classification\n",
        "## Exercise 3: Feature Extraction and Fine-Tuning\n",
        "**_Estimated completion time: 30 minutes_**\n",
        "\n",
        "In Exercise 1, we built a convnet from scratch, and were able to achieve an accuracy of about 70%. With the addition of data augmentation and dropout in Exercise 2, we were able to increase accuracy to about 80%. That seems decent, but 20% is still too high of an error rate. Maybe we just don't have enough training data available to properly solve the problem. What other approaches can we try?\n",
        "\n",
        "In this exercise, we'll look at two techniques for repurposing feature data generated from image models that have already been trained on large sets of data, **feature extraction** and **fine tuning**, and use them to improve the accuracy of our cat vs. dog classification model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI5rmt4UBwXs"
      },
      "source": [
        "## Feature Extraction Using a Pretrained Model\n",
        "\n",
        "One thing that is commonly done in computer vision is to take a model trained on a very large dataset, run it on your own, smaller dataset, and extract the intermediate representations (features) that the model generates. These representations are frequently informative for your own computer vision task, even though the task may be quite different from the problem that the original model was trained on. This versatility and repurposability of convnets is one of the most interesting aspects of deep learning.\n",
        "\n",
        "In our case, we will use the [Inception V3 model](https://arxiv.org/abs/1512.00567) developed at Google, and pre-trained on [ImageNet](http://image-net.org/), a large dataset of web images (1.4M images and 1000 classes). This is a powerful model; let's see what the features that it has learned can do for our cat vs. dog problem.\n",
        "\n",
        "First, we need to pick which intermediate layer of Inception V3 we will use for feature extraction. A common practice is to use the output of the very last layer before the `Flatten` operation, the so-called \"bottleneck layer.\" The reasoning here is that the following fully connected layers will be too specialized for the task the network was trained on, and thus the features learned by these layers won't be very useful for a new task. The bottleneck features, however, retain much generality.\n",
        "\n",
        "Let's instantiate an Inception V3 model preloaded with weights trained on ImageNet:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xJZ5glPPCRz"
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaXLMtYiF0t9"
      },
      "source": [
        "Now let's download the weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMrbllgAFipZ",
        "outputId": "9028b7d4-e8b4-4dac-dfd8-01393dd928d7"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-27 09:51:56--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.76.128, 66.102.1.128, 142.251.5.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.76.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   167MB/s    in 0.5s    \n",
            "\n",
            "2021-07-27 09:51:57 (167 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnRiGBfOF8rq"
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pre_trained_model = InceptionV3(\n",
        "    input_shape=(150, 150, 3), include_top=False, weights=None)\n",
        "pre_trained_model.load_weights(local_weights_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ5souMRZGjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "635cd2f4-ebae-4323-a2c3-2b4ac2c7b70b"
      },
      "source": [
        "\n",
        "pre_trained_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcYZPBS3bTAj"
      },
      "source": [
        "By specifying the `include_top=False` argument, we load a network that doesn't include the classification layers at the top—ideal for feature extraction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFxrqTuJee5m"
      },
      "source": [
        "Let's make the model non-trainable, since we will only use it for feature extraction; we won't update the weights of the pretrained model during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a38rB3lyedcB"
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGBGDiOAepnO"
      },
      "source": [
        "The layer we will use for feature extraction in Inception v3 is called `mixed7`. It is not the bottleneck of the network, but we are using it to keep a sufficiently large feature map (7x7 in this case). (Using the bottleneck layer would have resulting in a 3x3 feature map, which is a bit small.) Let's get the output from `mixed7`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj4rXshqbQlS",
        "outputId": "cda27f40-e9b6-403a-cb4f-4b2616bc9c30"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape: (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxHk6XQLeUWh"
      },
      "source": [
        "Now let's stick a fully connected classifier on top of `last_output`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMXb913pbvFg"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Configure and compile the model\n",
        "model = Model(pre_trained_model.input, x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=0.0001),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6ECjowwV5Ug"
      },
      "source": [
        "For examples and data preprocessing, let's use the same files and `train_generator` as we did in Exercise 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl-IqOTjZVw_"
      },
      "source": [
        "**NOTE:** The 2,000 images used in this exercise are excerpted from the [\"Dogs vs. Cats\" dataset](https://www.kaggle.com/c/dogs-vs-cats/data) available on Kaggle, which contains 25,000 images. Here, we use a subset of the full dataset to decrease training time for educational purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4s8HckqGlnb",
        "outputId": "c668428d-96d6-4ec1-8f13-f18ff3a981be"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "   https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip -O \\\n",
        "   /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-27 10:05:11--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.167.128, 74.125.133.128, 74.125.140.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.167.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  88.1MB/s    in 0.7s    \n",
            "\n",
            "2021-07-27 10:05:11 (88.1 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl9XXARuV_eg",
        "outputId": "e3375efb-85b8-489b-bf19-1a89e459eed3"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir, # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow validation images in batches of 20 using val_datagen generator\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEC1AL7iVRLz"
      },
      "source": [
        "Finally, let's train the model using the features we extracted. We'll train on all 2000 images available, for 2 epochs, and validate on all 1,000 validation images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Blhq2MAUeyGA",
        "outputId": "38ade2fe-7ac3-4f73-9338-87140cffb165"
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=2,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "100/100 - 55s - loss: 0.3246 - acc: 0.8720 - val_loss: 0.1234 - val_acc: 0.9560\n",
            "Epoch 2/2\n",
            "100/100 - 22s - loss: 0.2263 - acc: 0.9115 - val_loss: 0.1208 - val_acc: 0.9600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRjyAkE62aOG"
      },
      "source": [
        "You can see that we reach a validation accuracy of 88–90% very quickly. This is much better than the small model we trained from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt15y6IS2pBo"
      },
      "source": [
        "## Further Improving Accuracy with Fine-Tuning\n",
        "\n",
        "In our feature-extraction experiment, we only tried adding two classification layers on top of an Inception V3 layer. The weights of the pretrained network were not updated during training. One way to increase performance even further is to \"fine-tune\" the weights of the top layers of the pretrained model alongside the training of the top-level classifier. A couple of important notes on fine-tuning:\n",
        "\n",
        "- **Fine-tuning should only be attempted *after* you have trained the top-level classifier with the pretrained model set to non-trainable**. If you add a randomly initialized classifier on top of a pretrained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier), and your pretrained model will just forget everything it has learned.\n",
        "- Additionally, we **fine-tune only the *top layers* of the pre-trained model** rather than all layers of the pretrained model because, in a convnet, the higher up a layer is, the more specialized it is. The first few layers in a convnet learn very simple and generic features, which generalize to almost all types of images. But as you go higher up, the features are increasingly specific to the dataset that the model is trained on. The goal of fine-tuning is to adapt these specialized features to work with the new dataset.\n",
        "\n",
        "All we need to do to implement fine-tuning is to set the top layers of Inception V3 to be trainable, recompile the model (necessary for these changes to take effect), and resume training. Let's unfreeze all layers belonging to the `mixed7` module—i.e., all layers found after `mixed6`—and recompile the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l_J4S0Z2rgg",
        "outputId": "9f277c66-862b-4b83-9665-db85bc678afd"
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "unfreeze = False\n",
        "\n",
        "# Unfreeze all models after \"mixed6\"\n",
        "for layer in pre_trained_model.layers:\n",
        "  if unfreeze:\n",
        "    layer.trainable = True\n",
        "  if layer.name == 'mixed6':\n",
        "    unfreeze = True\n",
        "\n",
        "# As an optimizer, here we will use SGD \n",
        "# with a very low learning rate (0.00001)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=SGD(\n",
        "                  lr=0.00001, \n",
        "                  momentum=0.9),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE37ARlqY9da"
      },
      "source": [
        "Now let's retrain the model. We'll train on all 2000 images available, for 50 epochs, and validate on all 1,000 validation images. (This may take 15-20 minutes to run.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_GgDGG4Y_hJ",
        "outputId": "b6822afc-03e4-4444-985b-6e0998db0456"
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=50,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "100/100 - 29s - loss: 0.2300 - acc: 0.8980 - val_loss: 0.1133 - val_acc: 0.9550\n",
            "Epoch 2/50\n",
            "100/100 - 22s - loss: 0.2079 - acc: 0.9165 - val_loss: 0.1195 - val_acc: 0.9540\n",
            "Epoch 3/50\n",
            "100/100 - 23s - loss: 0.2168 - acc: 0.9095 - val_loss: 0.1222 - val_acc: 0.9540\n",
            "Epoch 4/50\n",
            "100/100 - 23s - loss: 0.2049 - acc: 0.9185 - val_loss: 0.1239 - val_acc: 0.9540\n",
            "Epoch 5/50\n",
            "100/100 - 22s - loss: 0.2022 - acc: 0.9095 - val_loss: 0.1237 - val_acc: 0.9540\n",
            "Epoch 6/50\n",
            "100/100 - 22s - loss: 0.2134 - acc: 0.9065 - val_loss: 0.1235 - val_acc: 0.9530\n",
            "Epoch 7/50\n",
            "100/100 - 22s - loss: 0.2020 - acc: 0.9190 - val_loss: 0.1232 - val_acc: 0.9530\n",
            "Epoch 8/50\n",
            "100/100 - 22s - loss: 0.1988 - acc: 0.9195 - val_loss: 0.1212 - val_acc: 0.9510\n",
            "Epoch 9/50\n",
            "100/100 - 23s - loss: 0.2119 - acc: 0.9000 - val_loss: 0.1212 - val_acc: 0.9520\n",
            "Epoch 10/50\n",
            "100/100 - 22s - loss: 0.1953 - acc: 0.9215 - val_loss: 0.1199 - val_acc: 0.9560\n",
            "Epoch 11/50\n",
            "100/100 - 23s - loss: 0.2170 - acc: 0.9020 - val_loss: 0.1201 - val_acc: 0.9530\n",
            "Epoch 12/50\n",
            "100/100 - 22s - loss: 0.2216 - acc: 0.9040 - val_loss: 0.1193 - val_acc: 0.9540\n",
            "Epoch 13/50\n",
            "100/100 - 23s - loss: 0.1829 - acc: 0.9280 - val_loss: 0.1181 - val_acc: 0.9580\n",
            "Epoch 14/50\n",
            "100/100 - 22s - loss: 0.2047 - acc: 0.9150 - val_loss: 0.1186 - val_acc: 0.9550\n",
            "Epoch 15/50\n",
            "100/100 - 22s - loss: 0.2089 - acc: 0.9130 - val_loss: 0.1169 - val_acc: 0.9570\n",
            "Epoch 16/50\n",
            "100/100 - 22s - loss: 0.2080 - acc: 0.9225 - val_loss: 0.1168 - val_acc: 0.9570\n",
            "Epoch 17/50\n",
            "100/100 - 22s - loss: 0.1994 - acc: 0.9125 - val_loss: 0.1159 - val_acc: 0.9590\n",
            "Epoch 18/50\n",
            "100/100 - 23s - loss: 0.2022 - acc: 0.9135 - val_loss: 0.1159 - val_acc: 0.9570\n",
            "Epoch 19/50\n",
            "100/100 - 22s - loss: 0.1984 - acc: 0.9180 - val_loss: 0.1156 - val_acc: 0.9580\n",
            "Epoch 20/50\n",
            "100/100 - 23s - loss: 0.2166 - acc: 0.9095 - val_loss: 0.1153 - val_acc: 0.9560\n",
            "Epoch 21/50\n",
            "100/100 - 22s - loss: 0.1939 - acc: 0.9220 - val_loss: 0.1162 - val_acc: 0.9540\n",
            "Epoch 22/50\n",
            "100/100 - 23s - loss: 0.1947 - acc: 0.9190 - val_loss: 0.1148 - val_acc: 0.9570\n",
            "Epoch 23/50\n",
            "100/100 - 22s - loss: 0.2017 - acc: 0.9130 - val_loss: 0.1144 - val_acc: 0.9590\n",
            "Epoch 24/50\n",
            "100/100 - 22s - loss: 0.2072 - acc: 0.9105 - val_loss: 0.1145 - val_acc: 0.9590\n",
            "Epoch 25/50\n",
            "100/100 - 22s - loss: 0.2014 - acc: 0.9175 - val_loss: 0.1135 - val_acc: 0.9580\n",
            "Epoch 26/50\n",
            "100/100 - 22s - loss: 0.1930 - acc: 0.9230 - val_loss: 0.1132 - val_acc: 0.9580\n",
            "Epoch 27/50\n",
            "100/100 - 22s - loss: 0.1820 - acc: 0.9245 - val_loss: 0.1127 - val_acc: 0.9600\n",
            "Epoch 28/50\n",
            "100/100 - 22s - loss: 0.1872 - acc: 0.9180 - val_loss: 0.1123 - val_acc: 0.9600\n",
            "Epoch 29/50\n",
            "100/100 - 22s - loss: 0.1995 - acc: 0.9135 - val_loss: 0.1122 - val_acc: 0.9590\n",
            "Epoch 30/50\n",
            "100/100 - 22s - loss: 0.1917 - acc: 0.9245 - val_loss: 0.1116 - val_acc: 0.9600\n",
            "Epoch 31/50\n",
            "100/100 - 23s - loss: 0.2039 - acc: 0.9115 - val_loss: 0.1111 - val_acc: 0.9600\n",
            "Epoch 32/50\n",
            "100/100 - 22s - loss: 0.2037 - acc: 0.9155 - val_loss: 0.1117 - val_acc: 0.9590\n",
            "Epoch 33/50\n",
            "100/100 - 23s - loss: 0.1920 - acc: 0.9190 - val_loss: 0.1111 - val_acc: 0.9600\n",
            "Epoch 34/50\n",
            "100/100 - 22s - loss: 0.1828 - acc: 0.9235 - val_loss: 0.1099 - val_acc: 0.9600\n",
            "Epoch 35/50\n",
            "100/100 - 23s - loss: 0.1928 - acc: 0.9170 - val_loss: 0.1101 - val_acc: 0.9600\n",
            "Epoch 36/50\n",
            "100/100 - 22s - loss: 0.1949 - acc: 0.9125 - val_loss: 0.1098 - val_acc: 0.9600\n",
            "Epoch 37/50\n",
            "100/100 - 22s - loss: 0.1948 - acc: 0.9185 - val_loss: 0.1090 - val_acc: 0.9610\n",
            "Epoch 38/50\n",
            "100/100 - 22s - loss: 0.1915 - acc: 0.9200 - val_loss: 0.1092 - val_acc: 0.9610\n",
            "Epoch 39/50\n",
            "100/100 - 22s - loss: 0.1968 - acc: 0.9170 - val_loss: 0.1086 - val_acc: 0.9610\n",
            "Epoch 40/50\n",
            "100/100 - 23s - loss: 0.1954 - acc: 0.9225 - val_loss: 0.1080 - val_acc: 0.9610\n",
            "Epoch 41/50\n",
            "100/100 - 22s - loss: 0.1905 - acc: 0.9180 - val_loss: 0.1081 - val_acc: 0.9610\n",
            "Epoch 42/50\n",
            "100/100 - 23s - loss: 0.2007 - acc: 0.9170 - val_loss: 0.1068 - val_acc: 0.9590\n",
            "Epoch 43/50\n",
            "100/100 - 22s - loss: 0.2044 - acc: 0.9130 - val_loss: 0.1076 - val_acc: 0.9610\n",
            "Epoch 44/50\n",
            "100/100 - 22s - loss: 0.1987 - acc: 0.9085 - val_loss: 0.1067 - val_acc: 0.9600\n",
            "Epoch 45/50\n",
            "100/100 - 22s - loss: 0.1804 - acc: 0.9305 - val_loss: 0.1062 - val_acc: 0.9590\n",
            "Epoch 46/50\n",
            "100/100 - 22s - loss: 0.2035 - acc: 0.9155 - val_loss: 0.1069 - val_acc: 0.9600\n",
            "Epoch 47/50\n",
            "100/100 - 23s - loss: 0.1991 - acc: 0.9170 - val_loss: 0.1068 - val_acc: 0.9590\n",
            "Epoch 48/50\n",
            "100/100 - 22s - loss: 0.1954 - acc: 0.9190 - val_loss: 0.1065 - val_acc: 0.9600\n",
            "Epoch 49/50\n",
            "100/100 - 23s - loss: 0.1829 - acc: 0.9270 - val_loss: 0.1059 - val_acc: 0.9600\n",
            "Epoch 50/50\n",
            "100/100 - 22s - loss: 0.1839 - acc: 0.9225 - val_loss: 0.1058 - val_acc: 0.9600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EPGn58ofwq5"
      },
      "source": [
        "We are seeing a nice improvement, with the validation loss going from ~1.7 down to ~1.2, and accuracy going from 88% to 92%. That's a 4.5% relative improvement in accuracy.\n",
        "\n",
        "Let's plot the training and validation loss and accuracy to show it conclusively:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "1FtxcKjJfxL9",
        "outputId": "8a15dff0-3043-427d-b44d-b1be01183181"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Retrieve a list of accuracy results on training and validation data\n",
        "# sets for each training epoch\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "# Retrieve a list of list results on training and validation data\n",
        "# sets for each training epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc)\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss)\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.title('Training and validation loss')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and validation loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-fUIeizakjE"
      },
      "source": [
        "Congratulations! Using feature extraction and fine-tuning, you've built an image classification model that can identify cats vs. dogs in images with over 90% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ANwJCnx7w-"
      },
      "source": [
        "## Clean Up\n",
        "\n",
        "Run the following cell to terminate the kernel and free memory resources:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hUmyohAyBzh"
      },
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v-IuBNrj_rC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}